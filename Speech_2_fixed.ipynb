{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zyYJdK97yPy",
    "outputId": "5a301253-a2ef-4461-a871-12543cb7c985"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to notebook --inplace --ClearOutputPreprocessor.enabled=True Speech_2.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSMzc-K9olKX",
    "outputId": "33c39974-16d0-43b3-bac7-5d7779f6eac1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXTc2KtNnMQ9",
    "outputId": "d67eb9a9-aedd-433a-b445-f059dad8f111"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchaudio librosa transformers matplotlib soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "38f8df6fdf3b4d12b245908f9278eb70",
      "f5fc3c3ec3df429aa886eae8387adbb0",
      "e82f255f40e645a885267f19cabcf999",
      "36705be527a14535bb6903b191b2ae1f",
      "dbb195c73a2c4acd9fdfc5c82491a4d1",
      "84dbb03c86164122a7b84e23cca58e1e",
      "3800c82cf23244b7b448d3e0dae40f42",
      "837d2d65d91f4b879f0a3ebfc4d21251",
      "6c7a039ea0434220a0ffbf344ec41e72",
      "7018dda52a6b4fc7a632df03a47bdd0b",
      "5565fd35777e46c08d434c9a05af1f21",
      "44948c6fd31347a3892727a237c76ad2",
      "248ceec94ec34102a6edcd48510041a0",
      "93d0e8c1453c4945b8d586dc18b981af",
      "40704e918d9a4b4197da9f3a91abac73",
      "56027dbb86874a00b55a8140405a34fc",
      "cfa334ae2784425587da45ba2f08d355",
      "19c4485724164931a4a8f5fc78881d58",
      "23e339ff9ad64b64a7fbf20217be7e92",
      "5b0e738b2eb64608a0c2f8410f792ae4",
      "711a10dd6d3d4e7b92662a0bf8c51c8a",
      "ada63b0502f641adb897c0c5b062c1aa",
      "db3f4832d4e14f43b12849c1dac77cd4",
      "db887f6851e047139817f17ac468d4f1",
      "d2670e1d618f4228b2ac8d7f0a8bbd33",
      "7e321ae6f6814abba7515506673ac408",
      "d821a4b7b7be48358e2fd55aa1559be4",
      "878f5db08516492995483e43665af246",
      "94ba36e9146f487db2b203d5b5a4143f",
      "00dfaa1f0bb24797ab7abad84b7fcfce",
      "9aabb692ebba436a84f5b895f4a0b32c",
      "911ea160cf2e42fe831a157416805885",
      "562c9e0822344ccfa1fa73a48b4e86c4",
      "cd7c0f72e31d4d62aa6d0aba65b72c7e",
      "b71dae0fbfdb487db030b55969bd5243",
      "ba9d688f612e4c098c459aa607c77a54",
      "527756e7a642421aa4d51ff48f9f3cd3",
      "ae940829fffc41b0a224b59fe0acb229",
      "19fd94f9f1674a2bb773f3e4d96a9a25",
      "a57b484ed12f4c898e8a777feed26d6a",
      "32d1c1b7f1cd416dba9242e43bd23226",
      "0af16ce670ae454fbcfa908cf7f30ad0",
      "927f4b2814584c7a8270bed5633964bc",
      "8da3a307eae84b4eaddea835f61600cd",
      "e5cc7712927a4024bb11604d3f341e3b",
      "721202af63a84d2fbc6b6489c29ac554",
      "adb0c177769a42c9970222c4a4907827",
      "837ef83135f84b27b8141e5355671574",
      "bd6e9eedd30c4e83985b651b0ea8efd5",
      "1d9d1351027442fb8bb21a68e38e78db",
      "341bf1007f3549fda03f3a8029f4beae",
      "439feb7c3e48409585b0b49519d0333c",
      "1aa3e32229e84b3599d476a5b9225cee",
      "d61e9a5522724f06b63d86bfa0056fb2",
      "d18c2a5ec44c43d7965585d23055cebf",
      "029bcb8868f0430cbd0afc546e931de3",
      "9b27b4e434cf41299670c2116f450f7c",
      "015f879be1d448c083304550f885a328",
      "d386c30b07e44b3daa979c4878c0e082",
      "6010db1c367148009f9556aff2aa796b",
      "0349be06e34547f1bfe1da90475e9f34",
      "73c1746808de4fbbb36db5087f10520c",
      "252e8b738aa34453a163f074bf22cd56",
      "f6ba86855e8748f4b403b15e2fddd7e1",
      "937315543caa4dc4aa15dd63bab3e16e",
      "6ba615e1fe764e8d848204d4a230af5a",
      "129cc29faf9645408121fd7ad83cfae4",
      "426e9e28c23f47d89b1db03861703a6d",
      "3ff01daf550d46519e792c26e858c2ec",
      "d7524961a689469cb4a7d7fe0f20fe0a",
      "0f0ffc1d5875405cac5c7162c065c333",
      "b3b8de11fcdc48caadd82cbbb5510f12",
      "07be918ea9b24524b31d45da45d60918",
      "e6b9992d81be42569f4cc44397de092f",
      "889ffde336934174ae0256d5761b9a53",
      "6fe38e69ebb2481e8db10e142fc9090d",
      "0f32d6bace5840329424d89c0f777a2c"
     ]
    },
    "id": "vdtn-1Z0pApp",
    "outputId": "a08535bf-2965-4ba7-ee87-f7df552c0095"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "audio_path = \"/content/drive/MyDrive/Speech-2/LJ050-0274.wav\"\n",
    "\n",
    "signal, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
    "\n",
    "print(\"Sample Rate:\", sr)\n",
    "print(\"Duration (sec):\", len(signal)/sr)\n",
    "\n",
    "time = np.arange(len(signal)) / sr\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(time, signal)\n",
    "plt.title(\"Speech Waveform (LJ Speech)\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "inputs = processor(signal, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "phonemes = processor.batch_decode(predicted_ids)\n",
    "\n",
    "print(\"Recognized Phonemes / Tokens:\")\n",
    "print(phonemes[0])\n",
    "\n",
    "num_tokens = predicted_ids.shape[1]\n",
    "total_duration = len(signal) / sr\n",
    "\n",
    "time_per_token = total_duration / num_tokens\n",
    "print(\"Approx time per phoneme (sec):\", time_per_token)\n",
    "\n",
    "# Example: extract phoneme at index 10\n",
    "phoneme_index = 10\n",
    "\n",
    "start_time = phoneme_index * time_per_token\n",
    "end_time = (phoneme_index + 1) * time_per_token\n",
    "\n",
    "start_sample = int(start_time * sr)\n",
    "end_sample = int(end_time * sr)\n",
    "\n",
    "phoneme_signal = signal[start_sample:end_sample]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(phoneme_signal)\n",
    "plt.title(f\"Extracted Phoneme (Index {phoneme_index})\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "\n",
    "sf.write(\"extracted_phoneme.wav\", phoneme_signal, sr)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
